# Problem description

Describe a crawler, then write code in ruby or Node.js to implement a crawler that takes the following arguments:

  * seed_url
  * max_simultaneous_request
  
The crawl should be a breadth first search with respect to seed_url and never have more than max_simultaneous_request requests running at once